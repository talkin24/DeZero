# TIL - Deep Learning from Scratch 3

## 제1고지: 미분자동계산

### Step1.

- `self.변수`는 인스턴스 변수

- 벡터를 다룰때 차원이라는 말에 주의. 3차원 벡터와 3차원 배열은 다른 뜻.

  

### Step2.

- `__call__` 메서드는 파이썬의 특수 메서드. 이 메서드를 정의하면 f = Function() 형태로 함수의 인스턴스를 변수 f에 대입해두고, 나중에 f(...) 형태로 `__call__` 메서드를 호출할 수 있음
- 상속해서 사용해야할 메서드를 직접 호출하지 않게 하기위해 예외를 발생시킬 수 있음.



### Step3.

- 계산그래프를 이용하면 각 변수에 대한 미분을 효율적으로 계산할 수 있음



### Step4.

- 수치미분: 극한을 이용할 수 없으니, 아주 미세한 차이를 이용하여 함수의 변화량을 구하는 방법
- 중앙차분: 수치미분에서 발생할 수밖에 없는 근사오차를 줄이기 위해 사용. f(x)와 f(x+h)의 차이를 구하는 대신, f(x-h)와 f(x+h)의 차이를 구함
  - 중앙차분에서 직선의 기울기는 f(x + h) - f(x - h) / 2h
- 해석적으로 계산한다고 함은 수식 변형만으로 답을 유도한다는 뜻
- 수치미분의 큰 문제1: 오차가 존재한다는 것. 수치미분에 오차가 포함되기 쉬운 이유는 '자릿수 누락'
- 수미치분의 큰 문제2: 계산량이 많음
- 위의 2가지 문제를 해결하기 위해 등장한 것이 backpropagation.
- 역전파는 복잡한 알고리즘이라 버그가 섞여들어가기가 쉬움. 그래서 역전파를 정확히 구현했는지 확인하기 위해 수치 미분의 결과를 이용(기울기 확인)



### Step5.

- 수치미분은 계산 비용과 정확도 면에서 문제가 있음 -> 역전파로 해결
- 역전파를 이용하면 미분을 효율적으로 계산할 수 있고 결괏값의 오차도 더 작음
- 합성함수의 미분은 구성 함수들이 미분의 곱으로 분해할 수 있음
- 출력에서 입력 방향으로 계산되는 이유는 y의 미분값을 전파하기 위해서, 즉 y를 중요요소로 대우하기 때문
- 머신러닝은 주로 대량의 매개변수를 입력받아 마지막 손실함수를 거쳐 출력을 내보냄
  - 이때 손실함수의 출력은 단일한 스칼라값이며, 이 값이 중요요소임
  - 따라서 손실함수의 각 매개변수에 대한 미분 계산이 필요한데, 이 경우 미분값을 출력에서 입력 방향으로 전파하면 한 번의 전파만으로 모든 매개변수에 대한 미분을 계산할 수 있음
  - 이렇게 계산이 효율적으로 이뤄지므로 미분을 반대방향으로 전파하는 방식을 이용함
- 순전파의 경우, 통상값. 역전파는 미분값 계산에 유리
- 역전파 시에는 순전파 시 이용한 데이터가 필요!
  - 따라서 역전파를 구현하기 위해선 순전파를 먼저 수행하고, 이때 각 함수가 입력 변수의 값을 기억해 두어야 함



### Step6.

- 순전파에서 input을 self.input에 저장하여 역전파 시 사용



### Step 7.

- Define-by-Run: 딥러닝에서 수행하는 계산들을 계산 시점에 '연결'하는 방식. '동적 계산 그래프'
-  리스트 데이터 구조를 응용하면 수행한 계산을 리스트에 추가해 나가는 것만으로 어떠한 계산 그래프의 역전파도 제대로 해낼 수 있음(웬거트 리스트)
- 변수 관점에서 함수는 창조자 혹은 부모
- 동적 계산 그래프는 실제로 계산이 이루어질 때 변수에 관련 '연결'을 기록하는 방식으로 만들어짐
- 연결된 Variable과 Function이 있다면 계산 그래프를 거꾸로 거슬러 올라갈 수 있음
- assert문은 그 평가 결과가 True가 아니면 예외가 발생. 따라서 조건을 충족하는지 여부를 확인하는데 사용할 수 있음
- 역전파 구현 순서
  1. 함수를 가져온다
  2. 함수의 입력을 가져온다
  3. 함수의 backward 메서드를 호출한다



### Step 8.

- 재귀를 반복으로 바꿈으로써 효율 개선 가능
- 재귀는 함수를 재귀적으로 호출할 때마다 중간 결과를 메모리에 유지하면서 처리를 이어감
- 따라서 반복문의 효율이 일반적으로 더 좋음. 그러나 메모리 성능의 확장으로 보통 재귀 사용은 크게 문제가 되진 않음



### Step 9.

- `np.ones_like()`는 입력 값과 형상과 데이터 타입이 같은 ndarray 인스턴스 생성. 전부 1로 채워줌.
- 0차원 ndarray 인스턴스를 사용하여 계산하면 결과 값이 numpy.float64나 dumpy.float32로 달라짐



### Step 10.

- 테스트를 해야 실수를 예방할 수 있으며, 테스트를 자동화해야 소프트웨어의 품질을 유지할 수 있음
- 파이썬으로 테스트할 때는 표준 라이브러리에 포함된 unittest를 사용하면 편함
- `unittest.TestCase.assertEqual` : 주어진 두 객체가 동일한지 판별
- `$python -m unittest 파일명` 처럼 -m unittest 인수를 제공하면 파이썬 파일을 테스트 모드로 실행할 수 있음

- 테스트 케이스가 많아질수록 square 함수의 신뢰도도 높아질 것임
- 기울기 확인: 수치 미분으로 구한 결과와 역전파로 구한 결과를 비교하여 그 차이가 크면 역전파 구현에 문제가 있다고 판단
- `np.allclose(a,b)` 는 ndarray 인스턴스인 a와 b의 값이 가까운지 판정(기울기를 확인하는 대상의 계산에 따라 인수를 미세하게 조정해야 할 수 있음)
- 테스트 파일들은 하나의 장소에 모아 관리하는 것이 일반적
- CI도구와 연계하면 소스 코드를 지속해서 테스트 할 수 있음
- 컴퓨터 프로그램에서 미분을 계산하는 방법은 크게 3가지
  1. 수치미분
     - 구현하기 쉬움
     - 출력에 오차가 포함되기 쉽고, 계산 비용이 높음
  2. 기호미분
     - 수식이 크게 부풀어 오르기 쉬움
  3. 자동미분
     - 연쇄법칙 활용 -> 효율적, 정밀하게 계산
     - 역전파도 자동미분에 속함
     - forward mode / reverse mode(역전파)





## 제2고지: 자연스러운 코드로

### Step 11.



### Step 12.

- 함수의 반환값이 한개라면 굳이 리스트로 반환하지 않게 코드를 짜는 것이 더 좋다
- 입력 인수 앞에 *을 붙이면 리스트를 사용하는 대신, 가변 길이 인수를 건네 함수를 호출할 수 있음
- 코드의 개선은 2가지 방향으로 이루어질 수 있음
  - 함수를 사용하는 사람을 위해
  - 함수를 구현하는 사람을 위해
- 함수를 호출할 때 *를 붙이면 리스트 언팩
  - ex) `xs = [x0, x1] `일 때, `self.forward(*xs)` 를 하면 `self.forward(x0, x1)` 로 호출하는 것과 동일하게 동작함

- 클래스를 파이썬 함수로 사용하기 위해 다음과 같이 코드를 짤 수 있다

  ```python
  def add(x0, x1):
  	return Add()(x0, x1)
  ```



### Step 13.

- 상류에서 흘러오는 미분값을 그대로 흘려보내는 것이 덧셈의 역전파

- 입력이 1개, 출력이 2개인 경우도 얼마든지 가능

  


### Step 14.

- 동일한 변수가 반복되어 사용되었을 때 문제 해결

- `+=` 를 대신 사용했을때 문제가 발생할 수 있다(because of 인플레이스 연산)

  - 누적대입연산자인 +=를 쓰면 변수의 객체 ID가 변하지 않음. 즉 메모리 위치가 동일하다는 뜻으로 값만 덮어쓰게 된것(= 인플레이스 연산)

  - 반면 `x = x + x` 를 실행하면 객체 ID가 달라짐 

  - 따라서 메모리 효율 측면에서는 인플레이스 연산이 우수함

  - 그러나 누적대입연산자는 객체의 값만 바뀌게 되므로, 기존 값까지 전부 변하게 됨

    ```python
    x = Variable(np.array(3))
    y = add(x,x)
    y.backward()
    
    print(y.grad, id(y.grad)) #  2, 4427494343
    print(x.grad, id(x.grad)) #  2, 4427494343
    ```

  - 누적대입연산자를 사용하지 않고 `x.grad = x.grad + gx` 로 수정 시 

    ```python
    print(y.grad, id(y.grad)) #  1, 4034494234
    print(x.grad, id(x.grad)) #  2, 4427494343 
    ```

    

- 동일 변수를 반복사용하여 '다른'계산을 할 때 생기는 문제 해결(메모리 절약을 위해)



### Step 15.

- 그래프의 연결된 상태를 위상(topology)라고 한다.
- 역전파 시 세대 수가 큰 쪽부터 처리하면 '부모'보다 '자식'이 먼저 처리됨을 보장할 수 있음



### Step 16.

- 함수의 출력값은 부모 세대 + 1
- 입력변수와 함수는 동일한 세대로 설정
  - 입력변수가 둘 이상이면 가장 큰 세대의 수를 선택
- 정렬 후 pop을 하는 것보다 우선순위 큐(heapq)를 사용하는 것이 더 효율적

- 중첩함수는 다음 두가지 조건을 충족할 때 적합함
  - 감싸는 메서드 안에서만 이용
  - 감싸는 메서드에 정의된 변수를 사용해야 한다.

